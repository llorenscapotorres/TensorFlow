{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a95099",
   "metadata": {},
   "source": [
    "**1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1192dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c904fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.cast(tf.range(-100, 100, 1), dtype=tf.float32)\n",
    "y = 2.3*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45b41c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(200,), dtype=float32, numpy=\n",
       " array([-100.,  -99.,  -98.,  -97.,  -96.,  -95.,  -94.,  -93.,  -92.,\n",
       "         -91.,  -90.,  -89.,  -88.,  -87.,  -86.,  -85.,  -84.,  -83.,\n",
       "         -82.,  -81.,  -80.,  -79.,  -78.,  -77.,  -76.,  -75.,  -74.,\n",
       "         -73.,  -72.,  -71.,  -70.,  -69.,  -68.,  -67.,  -66.,  -65.,\n",
       "         -64.,  -63.,  -62.,  -61.,  -60.,  -59.,  -58.,  -57.,  -56.,\n",
       "         -55.,  -54.,  -53.,  -52.,  -51.,  -50.,  -49.,  -48.,  -47.,\n",
       "         -46.,  -45.,  -44.,  -43.,  -42.,  -41.,  -40.,  -39.,  -38.,\n",
       "         -37.,  -36.,  -35.,  -34.,  -33.,  -32.,  -31.,  -30.,  -29.,\n",
       "         -28.,  -27.,  -26.,  -25.,  -24.,  -23.,  -22.,  -21.,  -20.,\n",
       "         -19.,  -18.,  -17.,  -16.,  -15.,  -14.,  -13.,  -12.,  -11.,\n",
       "         -10.,   -9.,   -8.,   -7.,   -6.,   -5.,   -4.,   -3.,   -2.,\n",
       "          -1.,    0.,    1.,    2.,    3.,    4.,    5.,    6.,    7.,\n",
       "           8.,    9.,   10.,   11.,   12.,   13.,   14.,   15.,   16.,\n",
       "          17.,   18.,   19.,   20.,   21.,   22.,   23.,   24.,   25.,\n",
       "          26.,   27.,   28.,   29.,   30.,   31.,   32.,   33.,   34.,\n",
       "          35.,   36.,   37.,   38.,   39.,   40.,   41.,   42.,   43.,\n",
       "          44.,   45.,   46.,   47.,   48.,   49.,   50.,   51.,   52.,\n",
       "          53.,   54.,   55.,   56.,   57.,   58.,   59.,   60.,   61.,\n",
       "          62.,   63.,   64.,   65.,   66.,   67.,   68.,   69.,   70.,\n",
       "          71.,   72.,   73.,   74.,   75.,   76.,   77.,   78.,   79.,\n",
       "          80.,   81.,   82.,   83.,   84.,   85.,   86.,   87.,   88.,\n",
       "          89.,   90.,   91.,   92.,   93.,   94.,   95.,   96.,   97.,\n",
       "          98.,   99.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(200,), dtype=float32, numpy=\n",
       " array([-230.       , -227.7      , -225.4      , -223.09999  ,\n",
       "        -220.79999  , -218.5      , -216.2      , -213.9      ,\n",
       "        -211.59999  , -209.3      , -207.       , -204.7      ,\n",
       "        -202.4      , -200.09999  , -197.8      , -195.5      ,\n",
       "        -193.2      , -190.9      , -188.59999  , -186.3      ,\n",
       "        -184.       , -181.7      , -179.4      , -177.09999  ,\n",
       "        -174.8      , -172.5      , -170.2      , -167.9      ,\n",
       "        -165.59999  , -163.3      , -161.       , -158.7      ,\n",
       "        -156.4      , -154.09999  , -151.8      , -149.5      ,\n",
       "        -147.2      , -144.9      , -142.59999  , -140.3      ,\n",
       "        -138.       , -135.7      , -133.4      , -131.09999  ,\n",
       "        -128.8      , -126.5      , -124.2      , -121.899994 ,\n",
       "        -119.6      , -117.299995 , -115.       , -112.7      ,\n",
       "        -110.399994 , -108.1      , -105.799995 , -103.5      ,\n",
       "        -101.2      ,  -98.9      ,  -96.6      ,  -94.299995 ,\n",
       "         -92.       ,  -89.7      ,  -87.4      ,  -85.1      ,\n",
       "         -82.799995 ,  -80.5      ,  -78.2      ,  -75.9      ,\n",
       "         -73.6      ,  -71.299995 ,  -69.       ,  -66.7      ,\n",
       "         -64.4      ,  -62.1      ,  -59.8      ,  -57.5      ,\n",
       "         -55.199997 ,  -52.899998 ,  -50.6      ,  -48.3      ,\n",
       "         -46.       ,  -43.7      ,  -41.399998 ,  -39.1      ,\n",
       "         -36.8      ,  -34.5      ,  -32.2      ,  -29.9      ,\n",
       "         -27.599998 ,  -25.3      ,  -23.       ,  -20.699999 ,\n",
       "         -18.4      ,  -16.1      ,  -13.799999 ,  -11.5      ,\n",
       "          -9.2      ,   -6.8999996,   -4.6      ,   -2.3      ,\n",
       "           0.       ,    2.3      ,    4.6      ,    6.8999996,\n",
       "           9.2      ,   11.5      ,   13.799999 ,   16.1      ,\n",
       "          18.4      ,   20.699999 ,   23.       ,   25.3      ,\n",
       "          27.599998 ,   29.9      ,   32.2      ,   34.5      ,\n",
       "          36.8      ,   39.1      ,   41.399998 ,   43.7      ,\n",
       "          46.       ,   48.3      ,   50.6      ,   52.899998 ,\n",
       "          55.199997 ,   57.5      ,   59.8      ,   62.1      ,\n",
       "          64.4      ,   66.7      ,   69.       ,   71.299995 ,\n",
       "          73.6      ,   75.9      ,   78.2      ,   80.5      ,\n",
       "          82.799995 ,   85.1      ,   87.4      ,   89.7      ,\n",
       "          92.       ,   94.299995 ,   96.6      ,   98.9      ,\n",
       "         101.2      ,  103.5      ,  105.799995 ,  108.1      ,\n",
       "         110.399994 ,  112.7      ,  115.       ,  117.299995 ,\n",
       "         119.6      ,  121.899994 ,  124.2      ,  126.5      ,\n",
       "         128.8      ,  131.09999  ,  133.4      ,  135.7      ,\n",
       "         138.       ,  140.3      ,  142.59999  ,  144.9      ,\n",
       "         147.2      ,  149.5      ,  151.8      ,  154.09999  ,\n",
       "         156.4      ,  158.7      ,  161.       ,  163.3      ,\n",
       "         165.59999  ,  167.9      ,  170.2      ,  172.5      ,\n",
       "         174.8      ,  177.09999  ,  179.4      ,  181.7      ,\n",
       "         184.       ,  186.3      ,  188.59999  ,  190.9      ,\n",
       "         193.2      ,  195.5      ,  197.8      ,  200.09999  ,\n",
       "         202.4      ,  204.7      ,  207.       ,  209.3      ,\n",
       "         211.59999  ,  213.9      ,  216.2      ,  218.5      ,\n",
       "         220.79999  ,  223.09999  ,  225.4      ,  227.7      ],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62ab6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:160]\n",
    "X_test = X[160:]\n",
    "y_train = y[:160]\n",
    "y_test = y[160:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baa27576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 63.4954 - mae: 63.4954\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 37.9030 - mae: 37.9030\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 42.5274 - mae: 42.5274\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.5824 - mae: 40.5824\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 46.8706 - mae: 46.8706\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.3425 - mae: 41.3425\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 44.7669 - mae: 44.7669\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.8193 - mae: 39.8193\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 49.1682 - mae: 49.1682\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.4094 - mae: 38.4094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26cec4a6290>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1973cbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 26.9385 - mae: 20.5381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[26.938549041748047, 20.5380802154541]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f04e35d",
   "metadata": {},
   "source": [
    "**2. Try building a neural network with 4 Dense layers and fitting it to your own regression datset, how does it perform?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67ba6564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 88.6492 - mae: 88.6492\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 78.5417 - mae: 78.5417\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 97.9379 - mae: 97.9379\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 97.1878 - mae: 97.1878\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 74.3915 - mae: 74.3915\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 95.7271 - mae: 95.7271\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 97.2980 - mae: 97.2980\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 98.1113 - mae: 98.1113\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 98.0671 - mae: 98.0671\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 98.0420 - mae: 98.0420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ced7002e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd63aaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 150.0084 - mae: 114.3598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[150.00840759277344, 114.35978698730469]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548021d5",
   "metadata": {},
   "source": [
    "**3. Try and improve the results we got on the insurance dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8738c78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance = pd.read_csv(\"insurance.csv\")\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4eadd265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colummn transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ")\n",
    "\n",
    "# Create X and y\n",
    "X = insurance.drop(\"charges\", axis=1)\n",
    "y = insurance[\"charges\"]\n",
    "\n",
    "# Build our train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the column transformer to our training data\n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c69d9ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 322219392.0000 - mae: 13337.9912\n",
      "Epoch 2/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 317690752.0000 - mae: 13174.9004\n",
      "Epoch 3/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 286078336.0000 - mae: 11972.0127\n",
      "Epoch 4/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 197020608.0000 - mae: 8812.0781\n",
      "Epoch 5/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 133300680.0000 - mae: 8646.2432\n",
      "Epoch 6/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 118900848.0000 - mae: 8397.1396\n",
      "Epoch 7/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 107904824.0000 - mae: 8032.9111\n",
      "Epoch 8/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 96902736.0000 - mae: 7658.5352\n",
      "Epoch 9/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 85799880.0000 - mae: 7150.8330\n",
      "Epoch 10/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 74468336.0000 - mae: 6804.7954\n",
      "Epoch 11/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 62852420.0000 - mae: 6141.7998\n",
      "Epoch 12/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 52719888.0000 - mae: 5640.4219\n",
      "Epoch 13/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 45244160.0000 - mae: 5107.6943\n",
      "Epoch 14/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 41304056.0000 - mae: 4708.5420\n",
      "Epoch 15/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 39657152.0000 - mae: 4448.2817\n",
      "Epoch 16/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 38926304.0000 - mae: 4146.0479\n",
      "Epoch 17/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 38730644.0000 - mae: 4180.7412\n",
      "Epoch 18/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 38469088.0000 - mae: 4051.4902\n",
      "Epoch 19/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 38338704.0000 - mae: 4157.6333\n",
      "Epoch 20/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 38203556.0000 - mae: 4035.7874\n",
      "Epoch 21/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 38244400.0000 - mae: 4127.4062\n",
      "Epoch 22/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 38316164.0000 - mae: 4109.7515\n",
      "Epoch 23/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 38186436.0000 - mae: 4185.4414\n",
      "Epoch 24/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 38098772.0000 - mae: 4071.4602\n",
      "Epoch 25/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37952416.0000 - mae: 4129.0127\n",
      "Epoch 26/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37826988.0000 - mae: 4064.0625\n",
      "Epoch 27/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37791964.0000 - mae: 4156.0220\n",
      "Epoch 28/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37794400.0000 - mae: 4059.8457\n",
      "Epoch 29/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37761848.0000 - mae: 4079.1611\n",
      "Epoch 30/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37812964.0000 - mae: 4128.1030\n",
      "Epoch 31/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37737508.0000 - mae: 4163.2373\n",
      "Epoch 32/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37692192.0000 - mae: 4151.5366\n",
      "Epoch 33/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37811028.0000 - mae: 4128.4014\n",
      "Epoch 34/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37576968.0000 - mae: 4085.6860\n",
      "Epoch 35/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37622716.0000 - mae: 4173.6533\n",
      "Epoch 36/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37522924.0000 - mae: 4108.1553\n",
      "Epoch 37/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37801100.0000 - mae: 4117.8677\n",
      "Epoch 38/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37639428.0000 - mae: 4200.5361\n",
      "Epoch 39/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37585040.0000 - mae: 4163.0679\n",
      "Epoch 40/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37589552.0000 - mae: 4140.5298\n",
      "Epoch 41/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37614380.0000 - mae: 4128.2007\n",
      "Epoch 42/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37620996.0000 - mae: 4162.3101\n",
      "Epoch 43/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37480376.0000 - mae: 4211.6816\n",
      "Epoch 44/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37579868.0000 - mae: 4127.5176\n",
      "Epoch 45/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37495020.0000 - mae: 4168.3970\n",
      "Epoch 46/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37657512.0000 - mae: 4151.0137\n",
      "Epoch 47/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37743584.0000 - mae: 4261.0005\n",
      "Epoch 48/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37524284.0000 - mae: 4130.6831\n",
      "Epoch 49/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37676836.0000 - mae: 4194.9731\n",
      "Epoch 50/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37595200.0000 - mae: 4230.2710\n",
      "Epoch 51/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37553132.0000 - mae: 4158.3975\n",
      "Epoch 52/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37517772.0000 - mae: 4160.1641\n",
      "Epoch 53/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37434292.0000 - mae: 4131.7329\n",
      "Epoch 54/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37880648.0000 - mae: 4250.9897\n",
      "Epoch 55/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37908540.0000 - mae: 4211.8301\n",
      "Epoch 56/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37512276.0000 - mae: 4214.9570\n",
      "Epoch 57/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37576524.0000 - mae: 4230.9375\n",
      "Epoch 58/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37522320.0000 - mae: 4136.5000\n",
      "Epoch 59/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37616744.0000 - mae: 4274.9556\n",
      "Epoch 60/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37685976.0000 - mae: 4151.4834\n",
      "Epoch 61/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37526796.0000 - mae: 4250.2998\n",
      "Epoch 62/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37487240.0000 - mae: 4153.7012\n",
      "Epoch 63/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37524696.0000 - mae: 4224.3506\n",
      "Epoch 64/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37499020.0000 - mae: 4209.3647\n",
      "Epoch 65/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37527860.0000 - mae: 4202.4819\n",
      "Epoch 66/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37457912.0000 - mae: 4185.5239\n",
      "Epoch 67/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37395708.0000 - mae: 4205.5400\n",
      "Epoch 68/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37421100.0000 - mae: 4174.8833\n",
      "Epoch 69/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37514296.0000 - mae: 4201.3521\n",
      "Epoch 70/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37460188.0000 - mae: 4201.8506\n",
      "Epoch 71/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37600256.0000 - mae: 4211.7373\n",
      "Epoch 72/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37438876.0000 - mae: 4204.6846\n",
      "Epoch 73/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37585316.0000 - mae: 4251.2852\n",
      "Epoch 74/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37467760.0000 - mae: 4207.1641\n",
      "Epoch 75/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37800624.0000 - mae: 4241.4937\n",
      "Epoch 76/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 38280816.0000 - mae: 4210.5566\n",
      "Epoch 77/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37540040.0000 - mae: 4186.5376\n",
      "Epoch 78/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37518748.0000 - mae: 4171.6333\n",
      "Epoch 79/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37743028.0000 - mae: 4261.9551\n",
      "Epoch 80/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37757624.0000 - mae: 4207.6030\n",
      "Epoch 81/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37911232.0000 - mae: 4214.8608\n",
      "Epoch 82/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37518556.0000 - mae: 4336.3408\n",
      "Epoch 83/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37889852.0000 - mae: 4180.4512\n",
      "Epoch 84/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37404440.0000 - mae: 4165.5728\n",
      "Epoch 85/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37303408.0000 - mae: 4207.6021\n",
      "Epoch 86/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37684112.0000 - mae: 4257.8379\n",
      "Epoch 87/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37488024.0000 - mae: 4220.4619\n",
      "Epoch 88/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37381588.0000 - mae: 4216.1138\n",
      "Epoch 89/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37478836.0000 - mae: 4165.9902\n",
      "Epoch 90/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37675908.0000 - mae: 4248.1128\n",
      "Epoch 91/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37423320.0000 - mae: 4189.1528\n",
      "Epoch 92/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37573988.0000 - mae: 4205.3208\n",
      "Epoch 93/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37456992.0000 - mae: 4256.9834\n",
      "Epoch 94/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37450412.0000 - mae: 4178.7881\n",
      "Epoch 95/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37470900.0000 - mae: 4207.5293\n",
      "Epoch 96/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37475328.0000 - mae: 4256.3164\n",
      "Epoch 97/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37567628.0000 - mae: 4186.5000\n",
      "Epoch 98/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37624588.0000 - mae: 4196.6211\n",
      "Epoch 99/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37639968.0000 - mae: 4215.8384\n",
      "Epoch 100/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37559444.0000 - mae: 4266.6616\n",
      "Epoch 101/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37468996.0000 - mae: 4183.5449\n",
      "Epoch 102/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37425596.0000 - mae: 4227.7407\n",
      "Epoch 103/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37651332.0000 - mae: 4194.7788\n",
      "Epoch 104/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37368840.0000 - mae: 4230.4751\n",
      "Epoch 105/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37566604.0000 - mae: 4193.9429\n",
      "Epoch 106/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37403808.0000 - mae: 4197.4985\n",
      "Epoch 107/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37471324.0000 - mae: 4217.1680\n",
      "Epoch 108/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37437120.0000 - mae: 4214.2319\n",
      "Epoch 109/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37464040.0000 - mae: 4200.4380\n",
      "Epoch 110/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37576184.0000 - mae: 4246.3154\n",
      "Epoch 111/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37515432.0000 - mae: 4168.9268\n",
      "Epoch 112/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37515608.0000 - mae: 4217.8403\n",
      "Epoch 113/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37471908.0000 - mae: 4223.8428\n",
      "Epoch 114/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37654660.0000 - mae: 4213.1743\n",
      "Epoch 115/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37495212.0000 - mae: 4221.7900\n",
      "Epoch 116/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37769648.0000 - mae: 4263.0601\n",
      "Epoch 117/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37488332.0000 - mae: 4220.5322\n",
      "Epoch 118/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37370820.0000 - mae: 4197.3955\n",
      "Epoch 119/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37619588.0000 - mae: 4217.4785\n",
      "Epoch 120/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37436692.0000 - mae: 4235.2329\n",
      "Epoch 121/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37451856.0000 - mae: 4182.2524\n",
      "Epoch 122/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37363956.0000 - mae: 4216.7505\n",
      "Epoch 123/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37523124.0000 - mae: 4233.2964\n",
      "Epoch 124/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37433328.0000 - mae: 4217.6694\n",
      "Epoch 125/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37365716.0000 - mae: 4201.7241\n",
      "Epoch 126/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37485276.0000 - mae: 4223.4609\n",
      "Epoch 127/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37607836.0000 - mae: 4225.0034\n",
      "Epoch 128/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37453440.0000 - mae: 4187.9102\n",
      "Epoch 129/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37688908.0000 - mae: 4292.9565\n",
      "Epoch 130/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37436584.0000 - mae: 4157.9272\n",
      "Epoch 131/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37371084.0000 - mae: 4223.6025\n",
      "Epoch 132/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37561780.0000 - mae: 4262.5708\n",
      "Epoch 133/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37492004.0000 - mae: 4186.7012\n",
      "Epoch 134/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37430728.0000 - mae: 4211.5166\n",
      "Epoch 135/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37473068.0000 - mae: 4225.6655\n",
      "Epoch 136/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37443952.0000 - mae: 4193.5698\n",
      "Epoch 137/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37548484.0000 - mae: 4215.7407\n",
      "Epoch 138/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37561780.0000 - mae: 4238.9722\n",
      "Epoch 139/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37579384.0000 - mae: 4230.9556\n",
      "Epoch 140/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37592228.0000 - mae: 4274.8032\n",
      "Epoch 141/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37801696.0000 - mae: 4250.4937\n",
      "Epoch 142/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37617176.0000 - mae: 4204.1948\n",
      "Epoch 143/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37592816.0000 - mae: 4186.6060\n",
      "Epoch 144/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37352488.0000 - mae: 4235.2661\n",
      "Epoch 145/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37406056.0000 - mae: 4266.9365\n",
      "Epoch 146/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 38056548.0000 - mae: 4257.4346\n",
      "Epoch 147/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37567448.0000 - mae: 4204.8813\n",
      "Epoch 148/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37535036.0000 - mae: 4255.0884\n",
      "Epoch 149/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37415060.0000 - mae: 4209.5107\n",
      "Epoch 150/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37387548.0000 - mae: 4221.8794\n",
      "Epoch 151/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37458500.0000 - mae: 4202.3198\n",
      "Epoch 152/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37545052.0000 - mae: 4258.3818\n",
      "Epoch 153/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37421388.0000 - mae: 4153.2026\n",
      "Epoch 154/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37438540.0000 - mae: 4282.2134\n",
      "Epoch 155/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37556976.0000 - mae: 4175.8296\n",
      "Epoch 156/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37658580.0000 - mae: 4250.7109\n",
      "Epoch 157/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37505844.0000 - mae: 4185.0029\n",
      "Epoch 158/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37632456.0000 - mae: 4245.2061\n",
      "Epoch 159/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37438832.0000 - mae: 4231.5381\n",
      "Epoch 160/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37492376.0000 - mae: 4199.2188\n",
      "Epoch 161/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37353432.0000 - mae: 4211.5000\n",
      "Epoch 162/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37498156.0000 - mae: 4202.2949\n",
      "Epoch 163/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37456504.0000 - mae: 4213.9707\n",
      "Epoch 164/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37583852.0000 - mae: 4236.1357\n",
      "Epoch 165/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37464620.0000 - mae: 4260.5229\n",
      "Epoch 166/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37489680.0000 - mae: 4203.0825\n",
      "Epoch 167/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37456004.0000 - mae: 4219.8877\n",
      "Epoch 168/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37468540.0000 - mae: 4203.2339\n",
      "Epoch 169/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37478176.0000 - mae: 4221.8730\n",
      "Epoch 170/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37669944.0000 - mae: 4260.2471\n",
      "Epoch 171/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37545120.0000 - mae: 4163.5957\n",
      "Epoch 172/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37522736.0000 - mae: 4307.2983\n",
      "Epoch 173/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37553448.0000 - mae: 4173.7690\n",
      "Epoch 174/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37531576.0000 - mae: 4207.8076\n",
      "Epoch 175/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37464300.0000 - mae: 4243.6147\n",
      "Epoch 176/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37515552.0000 - mae: 4231.9761\n",
      "Epoch 177/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37578264.0000 - mae: 4216.6665\n",
      "Epoch 178/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37492196.0000 - mae: 4170.6577\n",
      "Epoch 179/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37644056.0000 - mae: 4224.6108\n",
      "Epoch 180/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37548444.0000 - mae: 4280.2217\n",
      "Epoch 181/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37498956.0000 - mae: 4196.2686\n",
      "Epoch 182/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37475764.0000 - mae: 4218.7803\n",
      "Epoch 183/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37398076.0000 - mae: 4187.9531\n",
      "Epoch 184/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37545148.0000 - mae: 4204.5894\n",
      "Epoch 185/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37439112.0000 - mae: 4291.3467\n",
      "Epoch 186/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37482676.0000 - mae: 4154.6826\n",
      "Epoch 187/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37545224.0000 - mae: 4297.2520\n",
      "Epoch 188/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37633180.0000 - mae: 4184.0063\n",
      "Epoch 189/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37613524.0000 - mae: 4191.5581\n",
      "Epoch 190/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37534304.0000 - mae: 4220.4858\n",
      "Epoch 191/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 38207560.0000 - mae: 4288.7339\n",
      "Epoch 192/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37464320.0000 - mae: 4228.9067\n",
      "Epoch 193/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37423144.0000 - mae: 4188.6240\n",
      "Epoch 194/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37433444.0000 - mae: 4259.3848\n",
      "Epoch 195/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37369756.0000 - mae: 4179.4399\n",
      "Epoch 196/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37606180.0000 - mae: 4276.1499\n",
      "Epoch 197/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37568808.0000 - mae: 4201.1523\n",
      "Epoch 198/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37624844.0000 - mae: 4205.9126\n",
      "Epoch 199/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37558160.0000 - mae: 4267.2212\n",
      "Epoch 200/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37429352.0000 - mae: 4159.5415\n",
      "Epoch 201/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37430300.0000 - mae: 4252.2847\n",
      "Epoch 202/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37497032.0000 - mae: 4189.3755\n",
      "Epoch 203/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37496764.0000 - mae: 4275.9238\n",
      "Epoch 204/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37583768.0000 - mae: 4231.8896\n",
      "Epoch 205/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37447516.0000 - mae: 4184.1060\n",
      "Epoch 206/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37406664.0000 - mae: 4245.4019\n",
      "Epoch 207/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37437936.0000 - mae: 4174.4707\n",
      "Epoch 208/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37472116.0000 - mae: 4271.7593\n",
      "Epoch 209/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37455768.0000 - mae: 4201.8213\n",
      "Epoch 210/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37564508.0000 - mae: 4252.6934\n",
      "Epoch 211/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37603112.0000 - mae: 4203.9160\n",
      "Epoch 212/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37676664.0000 - mae: 4250.5112\n",
      "Epoch 213/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37442152.0000 - mae: 4237.2842\n",
      "Epoch 214/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37734816.0000 - mae: 4242.0610\n",
      "Epoch 215/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37516972.0000 - mae: 4173.5913\n",
      "Epoch 216/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37421012.0000 - mae: 4210.9604\n",
      "Epoch 217/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37524600.0000 - mae: 4199.6904\n",
      "Epoch 218/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37594764.0000 - mae: 4235.4199\n",
      "Epoch 219/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37553068.0000 - mae: 4256.7134\n",
      "Epoch 220/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37412736.0000 - mae: 4197.7388\n",
      "Epoch 221/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37455520.0000 - mae: 4223.9946\n",
      "Epoch 222/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37714252.0000 - mae: 4242.1445\n",
      "Epoch 223/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37427296.0000 - mae: 4176.9048\n",
      "Epoch 224/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37515104.0000 - mae: 4215.6743\n",
      "Epoch 225/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37487592.0000 - mae: 4223.4404\n",
      "Epoch 226/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37464324.0000 - mae: 4229.1577\n",
      "Epoch 227/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37453568.0000 - mae: 4205.6235\n",
      "Epoch 228/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37547668.0000 - mae: 4250.7002\n",
      "Epoch 229/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37618764.0000 - mae: 4258.7051\n",
      "Epoch 230/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37814776.0000 - mae: 4201.9287\n",
      "Epoch 231/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37399520.0000 - mae: 4204.9253\n",
      "Epoch 232/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37415040.0000 - mae: 4225.0610\n",
      "Epoch 233/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37443304.0000 - mae: 4212.3169\n",
      "Epoch 234/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37448988.0000 - mae: 4173.1309\n",
      "Epoch 235/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37509136.0000 - mae: 4265.0381\n",
      "Epoch 236/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37446836.0000 - mae: 4260.4653\n",
      "Epoch 237/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37576180.0000 - mae: 4218.8350\n",
      "Epoch 238/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37492128.0000 - mae: 4165.5059\n",
      "Epoch 239/300\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 37744900.0000 - mae: 4283.3696\n",
      "Epoch 240/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37473676.0000 - mae: 4215.0454\n",
      "Epoch 241/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37372684.0000 - mae: 4223.4663\n",
      "Epoch 242/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37483688.0000 - mae: 4249.6489\n",
      "Epoch 243/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37586512.0000 - mae: 4196.3188\n",
      "Epoch 244/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37534036.0000 - mae: 4229.9854\n",
      "Epoch 245/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37510764.0000 - mae: 4172.7407\n",
      "Epoch 246/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37597932.0000 - mae: 4272.8711\n",
      "Epoch 247/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37549728.0000 - mae: 4263.3638\n",
      "Epoch 248/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37520244.0000 - mae: 4195.3979\n",
      "Epoch 249/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37653432.0000 - mae: 4237.3013\n",
      "Epoch 250/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37471856.0000 - mae: 4219.9561\n",
      "Epoch 251/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37399916.0000 - mae: 4192.0659\n",
      "Epoch 252/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37572532.0000 - mae: 4237.1426\n",
      "Epoch 253/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37610908.0000 - mae: 4241.0103\n",
      "Epoch 254/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37584708.0000 - mae: 4211.0181\n",
      "Epoch 255/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37528516.0000 - mae: 4174.5195\n",
      "Epoch 256/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37502204.0000 - mae: 4265.6968\n",
      "Epoch 257/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37518552.0000 - mae: 4214.0684\n",
      "Epoch 258/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37668924.0000 - mae: 4222.8789\n",
      "Epoch 259/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37649584.0000 - mae: 4253.5498\n",
      "Epoch 260/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37457676.0000 - mae: 4203.0171\n",
      "Epoch 261/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37527756.0000 - mae: 4234.1177\n",
      "Epoch 262/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37445692.0000 - mae: 4230.1050\n",
      "Epoch 263/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37451884.0000 - mae: 4188.4160\n",
      "Epoch 264/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37520136.0000 - mae: 4227.5474\n",
      "Epoch 265/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37499988.0000 - mae: 4253.9048\n",
      "Epoch 266/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37746508.0000 - mae: 4244.1455\n",
      "Epoch 267/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37520164.0000 - mae: 4166.3320\n",
      "Epoch 268/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37410152.0000 - mae: 4282.7314\n",
      "Epoch 269/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37527080.0000 - mae: 4201.6665\n",
      "Epoch 270/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37464340.0000 - mae: 4196.0449\n",
      "Epoch 271/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37518376.0000 - mae: 4233.8081\n",
      "Epoch 272/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37407504.0000 - mae: 4285.5581\n",
      "Epoch 273/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37490256.0000 - mae: 4143.1855\n",
      "Epoch 274/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37549164.0000 - mae: 4286.9795\n",
      "Epoch 275/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37525888.0000 - mae: 4199.3638\n",
      "Epoch 276/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37582652.0000 - mae: 4220.5352\n",
      "Epoch 277/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37437084.0000 - mae: 4165.6187\n",
      "Epoch 278/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37718900.0000 - mae: 4240.3325\n",
      "Epoch 279/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37661664.0000 - mae: 4267.1553\n",
      "Epoch 280/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37482748.0000 - mae: 4232.5586\n",
      "Epoch 281/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37454628.0000 - mae: 4194.5908\n",
      "Epoch 282/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37398156.0000 - mae: 4225.1167\n",
      "Epoch 283/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37754872.0000 - mae: 4236.5513\n",
      "Epoch 284/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37468548.0000 - mae: 4194.9141\n",
      "Epoch 285/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37637712.0000 - mae: 4264.0381\n",
      "Epoch 286/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37617492.0000 - mae: 4266.7510\n",
      "Epoch 287/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37510532.0000 - mae: 4198.5039\n",
      "Epoch 288/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37438660.0000 - mae: 4214.3853\n",
      "Epoch 289/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37487148.0000 - mae: 4184.6245\n",
      "Epoch 290/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37685308.0000 - mae: 4237.8335\n",
      "Epoch 291/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37346984.0000 - mae: 4241.1128\n",
      "Epoch 292/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37706960.0000 - mae: 4208.4766\n",
      "Epoch 293/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37477840.0000 - mae: 4240.8813\n",
      "Epoch 294/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37498148.0000 - mae: 4229.4546\n",
      "Epoch 295/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37490124.0000 - mae: 4197.5503\n",
      "Epoch 296/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37549028.0000 - mae: 4210.6655\n",
      "Epoch 297/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37719928.0000 - mae: 4238.2764\n",
      "Epoch 298/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37596408.0000 - mae: 4225.6309\n",
      "Epoch 299/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37414884.0000 - mae: 4196.9087\n",
      "Epoch 300/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 37475760.0000 - mae: 4271.2236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26d029eabf0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(8),\n",
    "    tf.keras.layers.Dense(4),\n",
    "    tf.keras.layers.Dense(2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model.compile(loss=tf.keras.losses.mse,\n",
    "                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                        metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model.fit(X_train_normal, y_train, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d9c6a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 33781636.0000 - mae: 4099.2593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[33781636.0, 4099.25927734375]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c84fe09",
   "metadata": {},
   "source": [
    "**4. Import teh Boston pricing dataset from TensorFlow ``tf.keras.datasets`` and model it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "876aa78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path=\"boston_housing.npz\", test_split=0.2, seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a17f89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MinMaxScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b00f34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normal = scaler.transform(X_train)\n",
    "X_test_normal = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47ca3c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404, 13))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c07e8662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 14.4172 - mae: 14.4172\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.7635 - mae: 7.7635\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.9190 - mae: 5.9190\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.2028 - mae: 5.2028\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.8621 - mae: 4.8621\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.5691 - mae: 4.5691\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.2209 - mae: 4.2209\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.0745 - mae: 4.0745\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.8052 - mae: 3.8052\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.6675 - mae: 3.6675\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.4430 - mae: 3.4430\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3530 - mae: 3.3530\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4195 - mae: 3.4195\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3407 - mae: 3.3407\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4011 - mae: 3.4011\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3682 - mae: 3.3682\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3647 - mae: 3.3647\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.6501 - mae: 3.6501\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.5326 - mae: 3.5326\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3917 - mae: 3.3917\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2602 - mae: 3.2602\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3337 - mae: 3.3337\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4314 - mae: 3.4314\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4561 - mae: 3.4561\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2449 - mae: 3.2449\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2752 - mae: 3.2752\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3959 - mae: 3.3959\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2354 - mae: 3.2354\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2514 - mae: 3.2514\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4183 - mae: 3.4183\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2365 - mae: 3.2365\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.1946 - mae: 3.1946\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2502 - mae: 3.2502\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3031 - mae: 3.3031\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4099 - mae: 3.4099\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.6368 - mae: 3.6368\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3465 - mae: 3.3465\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3482 - mae: 3.3482\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3150 - mae: 3.3150\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4253 - mae: 3.4253\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2740 - mae: 3.2740\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3295 - mae: 3.3295\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.3053 - mae: 3.3053\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2000 - mae: 3.2000\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2723 - mae: 3.2723\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3953 - mae: 3.3953\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3932 - mae: 3.3932\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3351 - mae: 3.3351\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2784 - mae: 3.2784\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2528 - mae: 3.2528\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3534 - mae: 3.3534\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2719 - mae: 3.2719\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2002 - mae: 3.2002\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2290 - mae: 3.2290\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2602 - mae: 3.2602\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4450 - mae: 3.4450\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3338 - mae: 3.3338\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3393 - mae: 3.3393\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2803 - mae: 3.2803\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2451 - mae: 3.2451\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2359 - mae: 3.2359\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2536 - mae: 3.2536\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2979 - mae: 3.2979\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2142 - mae: 3.2142\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2339 - mae: 3.2339\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2716 - mae: 3.2716\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2069 - mae: 3.2069\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3485 - mae: 3.3485\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4518 - mae: 3.4518\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2601 - mae: 3.2601\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3447 - mae: 3.3447\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3136 - mae: 3.3136\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2299 - mae: 3.2299\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3068 - mae: 3.3068\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.5535 - mae: 3.5535\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3275 - mae: 3.3275\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3641 - mae: 3.3641\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3024 - mae: 3.3024\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2403 - mae: 3.2403\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3001 - mae: 3.3001\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3166 - mae: 3.3166\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3223 - mae: 3.3223\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3079 - mae: 3.3079\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2561 - mae: 3.2561\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.5174 - mae: 3.5174\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3002 - mae: 3.3002\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3094 - mae: 3.3094\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2768 - mae: 3.2768\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2212 - mae: 3.2212\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2712 - mae: 3.2712\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4385 - mae: 3.4385\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2989 - mae: 3.2989\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2167 - mae: 3.2167\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2759 - mae: 3.2759\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3004 - mae: 3.3004\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4739 - mae: 3.4739\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4405 - mae: 3.4405\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3638 - mae: 3.3638\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3058 - mae: 3.3058\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3025 - mae: 3.3025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26d292f0df0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_boston = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_boston.compile(loss=tf.keras.losses.mae,\n",
    "                     optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "                     metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_boston.fit(X_train_normal, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11d2a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8277 - mae: 2.8277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8276870250701904, 2.8276870250701904]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_boston.evaluate(X_test_normal, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
